<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>当你老了</title><link href="/" rel="alternate"></link><link href="/feeds/all.atom.xml" rel="self"></link><id>/</id><updated>2016-09-17T00:00:00+08:00</updated><entry><title>TextRank算法实现</title><link href="/posts/2016/09/17/textranksuan-fa-shi-xian.html" rel="alternate"></link><updated>2016-09-17T00:00:00+08:00</updated><author><name>lostfish</name></author><id>tag:,2016-09-17:posts/2016/09/17/textranksuan-fa-shi-xian.html</id><summary type="html">&lt;h3 id="_1"&gt;算法原理&lt;/h3&gt;
&lt;p&gt;TextRank算法主要用于文档的关键词抽取或者摘要抽取（本质是关键句抽取），原理就是PageRank的那一套思想，只不过构建图模型的时候稍有区别。&lt;/p&gt;
&lt;p&gt;抽取关键词的时候，图的节点为词，边为滑动窗口中共现的词对，边的权重为两个词在滑动窗口中的共现次数。不是所有的词都考虑，一般只选取特定词性的词，如名词，形容词和动词。同时，滑动窗口也有一个长度，比如连续5个词。&lt;/p&gt;
&lt;p&gt;抽取关键句的时候，图的节点为句子，边为文档中所有句子的两两组合，边的权重为两个句子的相似度，可分词后计算Jaccard相似度，或者更复杂点的提取语义向量计算余弦相似度，前者是原始论文[1]中的做法:
&lt;/p&gt;
&lt;div class="math"&gt;\begin{align*} 
Similarity(S_i,S_j)=\frac {|\{w_k|w_k\in S_i \&amp;amp; w_k\in S_j\}|}{log(|{S_i}|)+log(|S_j|)}
\end{align*}&lt;/div&gt;
&lt;p&gt;有了图模型，就可以迭代计算每个节点的权重，然后对节点进行排序。[1]中给出的公式为：&lt;/p&gt;
&lt;div class="math"&gt;\begin{align*} 
WS(V_i) = (1 - d) + d * \sum_{V_j\in In(V_i)} \frac{w_{ji}}{\sum_{V_k\in Out(V_j)} w_{jk}}WS(V_j)
\end{align*}&lt;/div&gt;
&lt;p&gt;原始PageRank公式为：&lt;/p&gt;
&lt;div class="math"&gt;\begin{align*} 
S(V_i) = (1 - d) + d * \sum_{j\in In(V_i)} \frac{1}{|Out(V_j)|}S(V_j)
\end{align*}&lt;/div&gt;
&lt;p&gt;可以看出主要区别为：在PageRank中边的权重都是1，而在TextRank中边的权重是变化的。&lt;/p&gt;
&lt;h3 id="_2"&gt;算法实现&lt;/h3&gt;
&lt;p&gt;由于算法原理比较简单，实现起来也比较容易，用C++实现了一个版本，github地址为：&lt;a href="https://github.com/lostfish/textrank"&gt;https://github.com/lostfish/textrank&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;实现的关键是构建图。为了简化，同时原始论文中的实验也说明有向图和无向图得到的结果相差不大，所以这里构建的是无向加权图。&lt;/p&gt;
&lt;p&gt;为节省空间，将词都映射为size_t类型的词&lt;span class="caps"&gt;ID&lt;/span&gt;。同时，用pair&lt;size_t, size_t&gt; 表示边，用map&lt;pair&lt;size_t, size_t&gt;, double&amp;gt; 存储边的权重。为计算方便，需要保留一个节点所有出度边的权重和，用map&lt;size_t, double&gt;来表示。&lt;/p&gt;
&lt;p&gt;核心rank的过程见text_rank.cpp中的函数CalcWordScore()，终止条件为两个：一个是两次迭代词权重的变化值小于预先设定的阈值，如0.0001，另一个是达到最大迭代次数，如100次。满足任一条件都终止继续迭代，实验中发现一般迭代几十次就会终止。&lt;/p&gt;
&lt;h3 id="_3"&gt;实验效果&lt;/h3&gt;
&lt;p&gt;仅仅和tf抽取的结果做了对比，没和tf-idf作对比是因为idf先验的获取依赖具体应用。实验数据集为新闻长文档，发现text_rank的效果比按照tf排序的结果稍好。&lt;/p&gt;
&lt;p&gt;具体实验数据待整理。&lt;/p&gt;
&lt;p&gt;貌似在具体的应用上，现在还没有特别好的关键词抽取算法，就是那种比经典的tf-idf算法效果好很多的。在一般抽取关键词的场景下，根据具体应用的数据，整理一份idf先验词表，然后用tf-idf算法其实就可以了。当然候选词要精心筛选，至少有根据词性过滤。&lt;/p&gt;
&lt;h3 id="_4"&gt;相关参考&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;[1] &lt;a href="http://acl.ldc.upenn.edu/acl2004/emnlp/pdf/Mihalcea.pdf"&gt;TextRank: Bringing Order into&amp;nbsp;Texts&lt;/a&gt;    &lt;/li&gt;
&lt;/ul&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }
    
    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript'; 
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="TextRank"></category><category term="关键词抽取"></category></entry><entry><title>Eclat算法实现</title><link href="/posts/2016/08/27/eclatsuan-fa-shi-xian.html" rel="alternate"></link><updated>2016-08-27T00:00:00+08:00</updated><author><name>lostfish</name></author><id>tag:,2016-08-27:posts/2016/08/27/eclatsuan-fa-shi-xian.html</id><summary type="html">&lt;h3 id="_1"&gt;基本原理&lt;/h3&gt;
&lt;p&gt;Eclat是挖掘频繁项集的一种算法，相比较而言远，它远没有另外两种算法Apriori和&lt;span class="caps"&gt;FP&lt;/span&gt;-Growth那么出名，一个直接的证明就是以前读书的时候课本都没有介绍。&lt;/p&gt;
&lt;p&gt;不过这个算法也有它自身的特点，基本原理和Apriori算法很相似，也是通过频繁K项集连接生成频繁K+1项集，但是比Apriori速度快很多，因为引入了倒排机制，保留了每个频繁项集对应的所有记录。这样，在连接生成频繁K+1项集的过程中，两个频繁K项集对应记录集合求交，就得到了这个K+1项集对应的记录集合，这个集合的size就是K+1项集的出现频数，通过与支持度比较就可以判断新产生的K+1项集是不是频繁的。从这个过程可以看出，Eclat算法只需要扫描一次记录库，而Apriori算法每次判断候选K+1项集是不是频繁的时候都要扫描一次记录库，所以Eclat比Apriori快也就不奇怪了。不难看出，Eclat算法其实是用空间换取了时间，后续实验也证明了这个算法是比较耗费空间的。&lt;/p&gt;
&lt;p&gt;举个例子（参考[1])：&amp;nbsp;有4条记录&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;tid item
1   A,B
2   B,C
3   A,C
4   A,B,C
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;设定最小支持度为2，第一边扫描记录库后，得到频繁1项集，其中每个item对应的记录集合也保留了，如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;item  tids  freq
A     1,3,4 3
B     1,2,4 3
C     2,3,4 3
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;由频繁1项集连接生成候选2项集，都是频繁的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;item tids freq
A,B  1,4  2
A,C  3,4  2
B,C  2,4  2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;由频繁2项集连接生成候选3项集，只有一个候选并且不是频繁的，算法结束：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;item    tids freq
A,B,C   4    1
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：在最后一步中，只有A,B和A,C前缀相同，可以连接&lt;/p&gt;
&lt;h3 id="_2"&gt;实现思路&lt;/h3&gt;
&lt;p&gt;尝试用C++进行了基本的实现。这里总结几个要点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;所有item都转换为整数表示，项集用存储item的有序vector表示，这样连接生成K+1项集的时候方便快速比较前缀&lt;/li&gt;
&lt;li&gt;每个频繁项集和记录集合的映射关系用map，记录集合用set（貌似比较耗费空间，可能用位图可以优化）&lt;/li&gt;
&lt;li&gt;连接过程关键是比较前缀，比如有两个K项集，那么比较前k-1项是否相同，相同就把其中一个K项集最后一项追加到另一个最后，构成K+1项集，追加后要保证K+1项集是有序的。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;从算法过程中还可以看出：频繁K项集的计算，需要把前面频繁1,2，..,&amp;nbsp;k-1项集都计算后才能进行。此外，频繁1项集和频繁2项集的计算需要特殊处理，不用比较前缀。&lt;/p&gt;
&lt;p&gt;具体实现参考代码：&lt;a href="https://github.com/lostfish/eclat"&gt;https://github.com/lostfish/eclat&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="_3"&gt;实验结果&lt;/h3&gt;
&lt;p&gt;测试数据采用和[2]相同的mushroom.dat，该数据集下载地址为[3]，下载后需要去掉每行最后的空格。&lt;/p&gt;
&lt;p&gt;机器配置为：Intel(R) Xeon(R) &lt;span class="caps"&gt;CPU&lt;/span&gt; E5606  @ 2.13GHz&amp;nbsp;(8核，32G内存)&lt;/p&gt;
&lt;p&gt;测试结果如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;最小支持度  频繁项集数  运行时间
812(0.1)    574513  29.219
1218(0.15)  98575   4.593
1624(0.2)   53663   2.632
2031(0.25)  5545    0.603
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;当支持度为812时，挖掘的各频繁项集数目如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;valid_num&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;8124&lt;/span&gt; &lt;span class="mi"&gt;8124&lt;/span&gt;
&lt;span class="n"&gt;uniq&lt;/span&gt; &lt;span class="n"&gt;id&lt;/span&gt; &lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;119&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    &lt;span class="mi"&gt;56&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    &lt;span class="mi"&gt;763&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    &lt;span class="mi"&gt;4599&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    &lt;span class="mi"&gt;16171&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    &lt;span class="mi"&gt;38829&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    &lt;span class="mi"&gt;69854&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    &lt;span class="mi"&gt;98852&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    &lt;span class="mi"&gt;111787&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    &lt;span class="mi"&gt;100660&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;   &lt;span class="mi"&gt;71342&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;   &lt;span class="mi"&gt;39171&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;   &lt;span class="mi"&gt;16292&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;   &lt;span class="mi"&gt;4956&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;   &lt;span class="mi"&gt;1039&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;   &lt;span class="mi"&gt;134&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;   &lt;span class="mi"&gt;8&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;同时还观察了下空间消耗，占用内存达到了将近9G，比较惊人。当然这个数据集合本身频繁模式就比较多，平时应用中一般也不需要计算所有频繁项集，一般到频繁3项集或4项集就够了。另外算法本身也可以优化，比如记录集合用位图来表示。&lt;/p&gt;
&lt;h3 id="_4"&gt;相关参考&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;[1] &lt;a href="https://zh.wikipedia.org/zh/%E5%85%B3%E8%81%94%E5%BC%8F%E8%A7%84%E5%88%99"&gt;https://zh.wikipedia.org/zh/%E5%85%B3%E8%81%94%E5%&lt;span class="caps"&gt;BC&lt;/span&gt;%8F%E8%A7%84%E5%88%99&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[2] &lt;a href="http://blog.csdn.net/yangliuy/article/details/7494983"&gt;http://blog.csdn.net/yangliuy/article/details/7494983&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[3] &lt;a href="http://blog.csdn.net/yangliuy/article/details/7494983"&gt;http://fimi.ua.ac.be/data/mushroom.dat&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="eclat"></category><category term="频繁项集挖掘"></category></entry><entry><title>python代理下载</title><link href="/posts/2016/07/22/pythondai-li-xia-zai.html" rel="alternate"></link><updated>2016-07-22T00:00:00+08:00</updated><author><name>lostfish</name></author><id>tag:,2016-07-22:posts/2016/07/22/pythondai-li-xia-zai.html</id><summary type="html">&lt;p&gt;当用同一个ip不断地去爬取一个网站的时候，很可能封掉，这时候就需要用到代理来分散请求。&lt;/p&gt;
&lt;h3 id="_1"&gt;分两种情况&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;代理设置了dns，调用函数crawl_page2()&lt;/li&gt;
&lt;li&gt;代理没有设置dns，调用函数crawl_page()，这种情况稍微复杂点，先要获取url域名对应的ip地址，给http请求包加上dest_ip字段&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="_2"&gt;代码如下&lt;/h3&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/usr/bin/env python&lt;/span&gt;
&lt;span class="c"&gt;# encoding:utf-8&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;urllib2&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;socket&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;struct&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_dest_ip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;domain&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;ip_addr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;socket&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gethostbyname&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;domain&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c"&gt;#just for ipv4&lt;/span&gt;
    &lt;span class="c"&gt;#ip_addr = socket.getaddrinfo(domain, &amp;#39;http&amp;#39;)[0][4][0]&lt;/span&gt;
    &lt;span class="c"&gt;#[(2, 1, 6, &amp;#39;&amp;#39;, (&amp;#39;14.215.177.38&amp;#39;, 80)), (2, 2, 17, &amp;#39;&amp;#39;, (&amp;#39;14.215.177.38&amp;#39;, 80)), (2, 1, 6, &amp;#39;&amp;#39;, (&amp;#39;14.215.177.37&amp;#39;, 80)), (2, 2, 17, &amp;#39;&amp;#39;, (&amp;#39;14.215.177.37&amp;#39;, 80))]&lt;/span&gt;
    &lt;span class="n"&gt;uint32_binary_str&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;socket&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;inet_aton&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ip_addr&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;unpack_result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;struct&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unpack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;!I&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;uint32_binary_str&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ip_int&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;socket&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;htonl&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;unpack_result&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; 
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;ip_int&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;crawl_page&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dest_ip&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cur_proxy&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
    &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;
    &lt;span class="n"&gt;myheaders&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;User-Agent&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.2; .NET CLR 1.0.3705;)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
        &lt;span class="s"&gt;&amp;quot;Proxy-Connection&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Keep-Alive&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s"&gt;&amp;quot;dest_ip&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;dest_ip&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;http://&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;cur_proxy&lt;/span&gt;
    &lt;span class="n"&gt;h&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ProxyHandler&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;http&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
    &lt;span class="n"&gt;o&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;build_opener&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;HTTPHandler&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;addheaders&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;myheaders&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;timeout&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;HTTPError&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Error Code:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;404&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;No page: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;URLError&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Error Reason:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reason&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;Exception&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Error&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Good&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Bad&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;content&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;crawl_page2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cur_proxy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;    get&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="c"&gt;#    print &amp;quot;--&amp;gt;crawl comment: %s&amp;quot; % url&lt;/span&gt;
&lt;span class="c"&gt;#    print &amp;quot;--&amp;gt;cur_proxy: %s&amp;quot; % cur_proxy&lt;/span&gt;
    &lt;span class="n"&gt;myheaders&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;User-Agent&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.2; .NET CLR 1.0.3705;)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;cur_proxy&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;proxy_handler&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ProxyHandler&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;http&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;cur_proxy&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
            &lt;span class="n"&gt;opener&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;build_opener&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;proxy_handler&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;opener&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;timeout&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;req&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Request&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;headers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;myheaders&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;req&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;timeout&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;HTTPError&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Error Code:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;404&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;No page: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;URLError&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Error Reason:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reason&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;Exception&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Error&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;content&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="c"&gt;# open proxys&lt;/span&gt;
    &lt;span class="n"&gt;proxy_list&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;readlines&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;http://www.baidu.com&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;host&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;www.baidu.com&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;dest_ip&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;get_dest_ip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;host&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;proxy_list&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;n1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;crawl_page&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dest_ip&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;crawl_page len:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n1&lt;/span&gt;
        &lt;span class="n"&gt;n2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;crawl_page2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;crawl_page2 len:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;h3 id="_3"&gt;测试输出&lt;/h3&gt;
&lt;p&gt;输入文件为两个代理ip，一个配置了dns，一个没有配置dns&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;Good    http://10.183.27.147:32810
crawl_page len: 10811
crawl_page2 len: 10811
Good    http://10.184.16.44:32810
crawl_page len: 10811
Error Reason: timed out
crawl_page2 len: 0
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="_4"&gt;其他说明&lt;/h3&gt;
&lt;p&gt;获取dest_ip是访问的dns服务，并不是访问的原网站，而dns是带本地cache，所以频繁访问应该是没有问题的。&lt;/p&gt;
&lt;p&gt;函数get_dest_ip()中调用了socket模块的相关函数:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;socket.gethostbyname()&amp;nbsp;获取域名对应ip，只支持ipv4，若需要支持ipv6，可使用函数socket.getaddrinfo()&lt;/li&gt;
&lt;li&gt;socket.inet_aton()&amp;nbsp;转换ip地址（192.168.1.10）为32位打包二进制字符串，只支持ipv4，若需要支持ipv6，可使用函数socket.inet_pton()&lt;/li&gt;
&lt;li&gt;socket.htonl()&amp;nbsp;将32位整数从主机字节序转换成网络字节序&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="_5"&gt;参考&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.programgo.com/article/11342723643/"&gt;http://www.programgo.com/article/11342723643/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cnblogs.com/gala/archive/2011/09/22/2184801.html"&gt;http://www.cnblogs.com/gala/archive/2011/09/22/2184801.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="python"></category><category term="代理"></category><category term="下载"></category></entry><entry><title>LDA算法理解</title><link href="/posts/2016/07/13/ldasuan-fa-li-jie.html" rel="alternate"></link><updated>2016-07-13T00:00:00+08:00</updated><author><name>lostfish</name></author><id>tag:,2016-07-13:posts/2016/07/13/ldasuan-fa-li-jie.html</id><summary type="html">&lt;h3 id="_1"&gt;引言&lt;/h3&gt;
&lt;p&gt;&lt;span class="caps"&gt;LDA&lt;/span&gt;相关的资料已经非常丰富，比较好的如[1], [2], [3], [4] 和&amp;nbsp;[5]。 &lt;/p&gt;
&lt;p&gt;[1]是一篇中文博文，核心的点都提到了，基本参考了[2], [3],&amp;nbsp;[4]的内容。&lt;/p&gt;
&lt;p&gt;[2]是一篇科普佳作，结合数学史，把&lt;span class="caps"&gt;LDA&lt;/span&gt;涉及的很多函数及背后的数据原理通俗地讲了一遍，适合慢慢品读。&lt;/p&gt;
&lt;p&gt;由于原始的&lt;span class="caps"&gt;LDA&lt;/span&gt;训练很慢，[3]主要讲了&lt;span class="caps"&gt;LDA&lt;/span&gt;的并行化实现，但是文献对&lt;span class="caps"&gt;LDA&lt;/span&gt;使用Gibbs采样涉及的公式进行了严密的推导，适合了解算法推导的每个环节。&lt;/p&gt;
&lt;p&gt;[4]是较早一篇比较详细讲解&lt;span class="caps"&gt;LDA&lt;/span&gt;的论文，基本上[1], [2], [3]都参考了该文献, 并且GibbsLDA++&amp;nbsp;的实现，也是主要参考该论文。&lt;/p&gt;
&lt;p&gt;[5]讲述了&lt;span class="caps"&gt;LDA&lt;/span&gt;涉及的概率图模型的更多相关知识，但是还是需要有一定概率图理论基础。&lt;/p&gt;
&lt;p&gt;总的来说，&lt;span class="caps"&gt;LDA&lt;/span&gt;算法的推导还是需要一定数理基础，但是Gibbs采样的实现却非常简单，伪代码一看就懂。&lt;/p&gt;
&lt;h3 id="_2"&gt;模型理解&lt;/h3&gt;
&lt;p&gt;简单地再次总结下要点。&lt;/p&gt;
&lt;p&gt;概率基础：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;多项分布&lt;/li&gt;
&lt;li&gt;狄利克雷分布：容易发现先验是狄利克雷分布，似然是多项分布，两者相乘得到的后验也是狄利克雷分布&lt;/li&gt;
&lt;li&gt;Delta函数，Gama函数： 狄利克雷分布函数中有一个Delta函数，有的地方也说Beta函数，可以表示成Gama函数的形式，而Gama(x+1) = x *&amp;nbsp;Game(x)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Gibbs Sampling&amp;nbsp;推导过程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;写出主题和词的联合概率公式，利用狄利克雷分布连乘部分积分等于Delta函数的性质，可以将联合分布只用Delta函数表示&lt;/li&gt;
&lt;li&gt;写出排除当前词主题的条件概率公式，其实就是1中得到的两个联合概率的比值，全部都是Delta函数，而Delta函数又都可以表示成Gama函数，利用Gama(x+1) = x *&amp;nbsp;Game(x)的性质，得到最终结果，这个就是Gibbs采样公式&lt;/li&gt;
&lt;li&gt;采样结束后，得到每篇文档每个词的主题，根据Dirichlet分布的期望，得到doc-topic这个多项分布的参数theta，以及topic-word这个多项分布的参数phi&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="gibbslda"&gt;GibbsLDA++代码剖析&lt;/h3&gt;
&lt;p&gt;相关编译和运行可以直接参考官方文档，这里只剖析一下代码。&lt;/p&gt;
&lt;p&gt;整个代码的实现偏C风格，结构很清晰，注释也很丰富。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;lda.cpp&amp;nbsp;主函数&lt;/li&gt;
&lt;li&gt;model.h&amp;nbsp;定义了类model，核心实现&lt;/li&gt;
&lt;li&gt;dataset.h&amp;nbsp;定义了类document和类dataset，存储输入文档数据&lt;/li&gt;
&lt;li&gt;constants.h 定义了&lt;span class="caps"&gt;BUFF&lt;/span&gt;值和模型状态值&lt;/li&gt;
&lt;li&gt;strtokenizer.h&amp;nbsp;定义类strtokenizer，分割文本并保存token&lt;/li&gt;
&lt;li&gt;utils.h 定义类&amp;nbsp;utils，包含解析参数，生成模型保存名称，排序等函数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;主要是理解类model的实现，&lt;span class="caps"&gt;LDA&lt;/span&gt;训练相关参数如下，其中alpha和beta对K维都是一样的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;// --- model parameters and variables ---    
int M; // dataset size (i.e., number of docs)
int V; // vocabulary size
int K; // number of topics
double alpha, beta; // LDA hyperparameters 
int niters; // number of Gibbs sampling iterations
int liter; // the iteration at which the model was saved
int savestep; // saving period
int twords; // print out top words per each topic
int withrawstrs;

double * p; // temp variable for sampling
int ** z; // topic assignments for words, size M x doc.size()
int ** nw; // cwt[i][j]: number of instances of word/term i assigned to topic j, size V x K
int ** nd; // na[i][j]: number of words in document i assigned to topic j, size M x K
int * nwsum; // nwsum[j]: total number of words assigned to topic j, size K
int * ndsum; // nasum[i]: total number of words in document i, size M
double ** theta; // theta: document-topic distributions, size M x K
double ** phi; // phi: topic-word distributions, size K x V
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;关键函数如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;// init for estimation
int init_est();
int init_estc();

// estimate LDA model using Gibbs sampling
void estimate();
int sampling(int m, int n);
void compute_theta();
void compute_phi();
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;init_est()从头开始训练，init_estc()继续训练。文档为M，词表为V，主题数为K，初始状态下，每个词对主题k的数目nw[w][k]都为0，每个文档对主题k的数目nd[m][k]也都为0，每个主题的数目nwsum[k]均为0，每篇文档的词数ndsum[m]均为0。然后对于每篇文档的每个词，随机采样一个主题，更新数组nw, nd, nwsum, ndsum。theta数组为M*K，&amp;nbsp;phi数组为K*V。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;z = new int*[M];
for (m = 0; m &amp;lt; ptrndata-&amp;gt;M; m++) {
int N = ptrndata-&amp;gt;docs[m]-&amp;gt;length;
z[m] = new int[N];

    // initialize for z
    for (n = 0; n &amp;lt; N; n++) {
        int topic = (int)(((double)random() / RAND_MAX) * K);
        z[m][n] = topic;

        // number of instances of word i assigned to topic j
        nw[ptrndata-&amp;gt;docs[m]-&amp;gt;words[n]][topic] += 1;
        // number of words in document i assigned to topic j
        nd[m][topic] += 1;
        // total number of words assigned to topic j
        nwsum[topic] += 1;
    } 
    // total number of words in document i
    ndsum[m] = N;      
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;estimate()进行训练，对于每篇文档的每个词，采样一个主题，然后保存模型，并且计算theta和phi：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;// for all z_i
for (int m = 0; m &amp;lt; M; m++) {
    for (int n = 0; n &amp;lt; ptrndata-&amp;gt;docs[m]-&amp;gt;length; n++) {
    // (z_i = z[m][n])
    // sample from p(z_i|z_-i, w)
    int topic = sampling(m, n);
    z[m][n] = topic;
    }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;sampling(int m, int&amp;nbsp;n)函数使用Gibbs采样公式计算当前词的主题分布，然后随机选择一个主题，用到了累计概率值高于随机值的方式，类似轮盘赌：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;int model::sampling(int m, int n) {
    // remove z_i from the count variables
    int topic = z[m][n];
    int w = ptrndata-&amp;gt;docs[m]-&amp;gt;words[n];
    nw[w][topic] -= 1;
    nd[m][topic] -= 1;
    nwsum[topic] -= 1;
    ndsum[m] -= 1;

    double Vbeta = V * beta;
    double Kalpha = K * alpha;    
    // do multinomial sampling via cumulative method
    for (int k = 0; k &amp;lt; K; k++) {
    p[k] = (nw[w][k] + beta) / (nwsum[k] + Vbeta) *
            (nd[m][k] + alpha) / (ndsum[m] + Kalpha);
    }
    // cumulate multinomial parameters
    for (int k = 1; k &amp;lt; K; k++) {
    p[k] += p[k - 1];
    }
    // scaled sample because of unnormalized p[]
    double u = ((double)random() / RAND_MAX) * p[K - 1];

    for (topic = 0; topic &amp;lt; K; topic++) {
    if (p[topic] &amp;gt; u) {
        break;
    }
    }

    // add newly estimated z_i to count variables
    nw[w][topic] += 1;
    nd[m][topic] += 1;
    nwsum[topic] += 1;
    ndsum[m] += 1;

    return topic;
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;compute_theta()函数调用了推导公式：
&lt;/p&gt;
&lt;div class="math"&gt;\begin{align*} 
\hat{\theta}_{mk} &amp;amp;= \frac{n_{m}^{(k)} + \alpha_k}{\sum_{k=1}^K (n_{m}^{(k)} + \alpha_k)} 
\end{align*}&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;for (int m = 0; m &amp;lt; M; m++) {
for (int k = 0; k &amp;lt; K; k++) {
    theta[m][k] = (nd[m][k] + alpha) / (ndsum[m] + K * alpha);
}
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;compute_phi()函数调用了推导公式：
&lt;/p&gt;
&lt;div class="math"&gt;\begin{align*} 
\hat{\varphi}_{kw} &amp;amp;= \frac{n_{k}^{(w)} + \beta_t}{\sum_{w=1}^V (n_{k}^{(w)} + \beta_w)} 
\end{align*}&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;for (int k = 0; k &amp;lt; K; k++) {
for (int w = 0; w &amp;lt; V; w++) {
    phi[k][w] = (nw[w][k] + beta) / (nwsum[k] + V * beta);
}
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;对新的数据推导主题分布时，重新走了一遍Gibbs采样，相应的计算theta和phi的公式不变，但有略微调整，这里不再赘述。&lt;/p&gt;
&lt;h3 id="lda"&gt;&lt;span class="caps"&gt;LDA&lt;/span&gt;开源工具包&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://gibbslda.sourceforge.net/"&gt;GibbsLDA++&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://code.google.com/p/plda/"&gt;plda&lt;/a&gt; (&lt;a href="https://github.com/openbigdatagroup/plda"&gt;地址2&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="_3"&gt;相关参考&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;[1] &lt;a href="http://blog.csdn.net/yangliuy/article/details/8302599"&gt;概率语言模型及其变形系列(2)-&lt;span class="caps"&gt;LDA&lt;/span&gt;及Gibbs&amp;nbsp;Sampling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[2] &lt;a href="http://www.52nlp.cn/lda-math-%E6%B1%87%E6%80%BB-lda%E6%95%B0%E5%AD%A6%E5%85%AB%E5%8D%A6"&gt;&lt;span class="caps"&gt;LDA&lt;/span&gt;数学八卦&lt;/a&gt; (&lt;a href="http://vdisk.weibo.com/s/q0sGh/1360334108"&gt;pdf&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;[3] Distributed Gibbs Sampling of Latent Topic
Models: The Gritty Details (&lt;a href="https://cxwangyi.files.wordpress.com/2012/01/llt.pdf"&gt;pdf&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;[4] Parameter estimation for text analysis (&lt;a href="http://www.arbylon.net/publications/text-est.pdf"&gt;pdf&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;[5] Graphical Representation, Generative Model and Gibbs Sampling (&lt;a href="http://home.in.tum.de/~xiaoh/pub/3G_talk.pdf"&gt;pdf&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }
    
    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript'; 
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="lda"></category><category term="主题模型"></category></entry><entry><title>青海行</title><link href="/posts/2016/07/03/qing-hai-xing.html" rel="alternate"></link><updated>2016-07-03T00:00:00+08:00</updated><author><name>lostfish</name></author><id>tag:,2016-07-03:posts/2016/07/03/qing-hai-xing.html</id><summary type="html">&lt;p&gt;六月是个好月份，适合旅行。&lt;/p&gt;
&lt;p&gt;从22号到26号共五天的时间里，跟团去大青海体验了祖国西部的大好河山。&lt;/p&gt;
&lt;h3 id="_1"&gt;启程&lt;/h3&gt;
&lt;p&gt;傍晚时分，天气正好，带一丝燥热，跟随大队伍从深圳宝启程啦。
&lt;img alt="青海" src="/images/qinghai1_hai.png" /&gt;&lt;/p&gt;
&lt;p&gt;有点漫长的旅程，飞着飞着天就黑了。&lt;/p&gt;
&lt;p&gt;到西宁的时候，已经是午夜。一下飞机就感受到了大西部的寒冷。后面更是感觉到了干燥和缺氧。&lt;/p&gt;
&lt;h3 id="_2"&gt;第一站&lt;/h3&gt;
&lt;p&gt;青海湖，美，辽阔，Relaxing！&lt;/p&gt;
&lt;h3 id="_3"&gt;第二站&lt;/h3&gt;
&lt;p&gt;茶卡盐湖，白，天空之境，特别的美。&lt;/p&gt;
&lt;h3 id="_4"&gt;第三站&lt;/h3&gt;
&lt;p&gt;沙岛，还是青海湖，但是体验沙漠游玩项目：骑骆驼，骑摩托，滑沙。&lt;/p&gt;
&lt;h3 id="_5"&gt;最后一站&lt;/h3&gt;
&lt;p&gt;彩虹部落&lt;/p&gt;</summary><category term="qinghai"></category><category term="travel"></category></entry><entry><title>sklearn使用笔记</title><link href="/posts/2015/07/04/sklearnshi-yong-bi-ji.html" rel="alternate"></link><updated>2015-07-04T00:00:00+08:00</updated><author><name>lostfish</name></author><id>tag:,2015-07-04:posts/2015/07/04/sklearnshi-yong-bi-ji.html</id><summary type="html">&lt;p&gt;sklearn全称为scikit-learn，是目前很流行的一个基于python的机器学习包，基本覆盖了常见的机器学习算法，如分类、回归、聚类、特征选择、模型选择以及数据预处理等任务对应的算法。文档和示例非常丰富，可视化展示也很方便，所以使用者众多，尤其是在 &lt;a href="https://www.kaggle.com/"&gt;Kaggle&lt;/a&gt;&amp;nbsp;数据分析竞赛中被参赛者广泛使用。&lt;/p&gt;
&lt;p&gt;关于该工具包的使用介绍网上已经非常多，所以这里只是整理和记录自己使用的一些心得。&lt;/p&gt;
&lt;h3 id="_1"&gt;初始入门&lt;/h3&gt;
&lt;p&gt;最好入门方法就是参考官网的 &lt;a href="http://scikit-learn.org/stable/tutorial/index.html"&gt;Tutorials&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;sklearn集成了一些常用的数据集，以方便测试相关算法，封装为datasets模块，如导入分类数据集合iris和digits，导入回归数据集diabetes&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;
&lt;span class="n"&gt;iris&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load_iris&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;digits&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load_digits&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;diabetes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load_diabetes&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;具体如何在这些数据集合应用相关算法，官网Tutorials有详细的介绍，下面重点讲下文本分类。&lt;/p&gt;
&lt;h3 id="_2"&gt;文本分类&lt;/h3&gt;
&lt;h4 id="1"&gt;1.&amp;nbsp;加载数据&lt;/h4&gt;
&lt;p&gt;数据集选取的是20newsgroups，该数据集包含20个新闻组约2万篇文档，加载方式也是通过sklearn.datasets模块，但是稍有不同，如下&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;fetch_20newsgroups&lt;/span&gt;
&lt;span class="n"&gt;twenty_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fetch_20newsgroups&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;subset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;train&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shuffle&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;从上面可以看出，加载数据集实际上是调用函数fetch_20newsgroups()&lt;/p&gt;
&lt;p&gt;在python命令行输入help(fetch_20newsgroups），可以查看相应参数说明，其中&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;subset: 指定加载训练集或测试集，或者两者，取值对应&amp;#8217;train&amp;#8217;, &amp;#8216;test&amp;#8217;,&amp;nbsp;&amp;#8216;all&amp;#8217;&lt;/li&gt;
&lt;li&gt;data_home: 指定20newsgroups数据集所在路径，默认为&amp;nbsp;&amp;#8216;~/scikit_learn_data&amp;#8217;，Windows下对应为C:\Users\xxx\scikit_learn_data&lt;/li&gt;
&lt;li&gt;categories:&amp;nbsp;指定要加载的类别list，默认为None，表示所有类别&lt;/li&gt;
&lt;li&gt;shuffle：&amp;nbsp;是否要混洗数据&lt;/li&gt;
&lt;li&gt;random_state：&amp;nbsp;混洗随机数的种子值&lt;/li&gt;
&lt;li&gt;download_if_missing：&amp;nbsp;指定data_home下不存在数据集时是否下载，默认为True，表示下载&lt;/li&gt;
&lt;li&gt;remove： 指定预处理文本的过滤策略，取值为元组 (&amp;#8216;headers&amp;#8217;, &amp;#8216;footers&amp;#8217;,&amp;nbsp;&amp;#8216;quotes&amp;#8217;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;刚开始测试这个数据集的时候，老是等半天没有结果。于是看了下对应的源代码./site-packages/sklearn/datasets/twenty_newsgroups.py，发现第一次加载的时候会下载数据集到~/scikit_learn_data/20news_home，下载完成后会解压然后压缩生成cache文件，即~/scikit_learn_data/20news-bydate.pkz，以后每次加载就读取该文件了。&lt;/p&gt;
&lt;p&gt;所以首次加载的时候需要有点耐心，大概等待7分钟左右吧（国内环境）。&lt;/p&gt;
&lt;p&gt;当然也可以自己下载放到目录~/scikit_learn_data/20news_home，下载地址为：&lt;a href="http://people.csail.mit.edu/jrennie/20Newsgroups/20news-bydate.tar.gz"&gt;http://people.csail.mit.edu/jrennie/20Newsgroups/20news-bydate.tar.gz&lt;/a&gt;&amp;nbsp;（文件大小为13.7M）&lt;/p&gt;
&lt;h4 id="2"&gt;2.&amp;nbsp;特征选择&lt;/h4&gt;
&lt;p&gt;最常见的就是词袋模型，每个词就是一个特征，特征权重为词频，通过构建&lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer"&gt;CountVectorizer&lt;/a&gt;&amp;nbsp;来向量化每篇文档：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.feature_extraction.text&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;CountVectorizer&lt;/span&gt;

&lt;span class="n"&gt;vectorizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;CountVectorizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;min_df&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;corpus&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
    &lt;span class="s"&gt;&amp;#39;This is the first document.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s"&gt;&amp;#39;This is the second second document.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s"&gt;&amp;#39;And the third one.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s"&gt;&amp;#39;Is this the first document?&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;vectorizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;corpus&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;vectorizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_feature_names&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="c"&gt;#[u&amp;#39;and&amp;#39;, u&amp;#39;document&amp;#39;, u&amp;#39;first&amp;#39;, u&amp;#39;is&amp;#39;, \&lt;/span&gt;
&lt;span class="c"&gt;#u&amp;#39;one&amp;#39;, u&amp;#39;second&amp;#39;, u&amp;#39;the&amp;#39;, u&amp;#39;third&amp;#39;, u&amp;#39;this&amp;#39;]&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vectorizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocabulary_&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c"&gt;# and   0&lt;/span&gt;
&lt;span class="c"&gt;# document  1&lt;/span&gt;
&lt;span class="c"&gt;# first 2&lt;/span&gt;
&lt;span class="c"&gt;# is    3&lt;/span&gt;
&lt;span class="c"&gt;# one   4&lt;/span&gt;
&lt;span class="c"&gt;# second    5&lt;/span&gt;
&lt;span class="c"&gt;# the   6&lt;/span&gt;
&lt;span class="c"&gt;# third 7&lt;/span&gt;
&lt;span class="c"&gt;# this  8&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;toarray&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="c"&gt;# [[0 1 1 1 0 0 1 0 1]]&lt;/span&gt;
&lt;span class="c"&gt;# [[0 1 0 1 0 2 1 0 1]]&lt;/span&gt;
&lt;span class="c"&gt;# [[1 0 0 0 1 0 1 1 0]]&lt;/span&gt;
&lt;span class="c"&gt;# [[0 1 1 1 0 0 1 0 1]]&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;vectorizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transform&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Something completely new.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;toarray&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="c"&gt;# [[0 0 0 0 0 0 0 0 0]]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;上面代码中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;函数fit_transform()会在训练数据上训练一个Vectorizer，并将训练数据向量化，由于文本特征维度较高，这里是用稀疏矩阵保存&lt;/li&gt;
&lt;li&gt;函数get_feature_names()得到特征名称的list,&amp;nbsp;特征名称为unicode字符串，而vectorizer的成员变量vocabulary_恰好是特征名称到特征索引的dict，这个索引就是get_feature_names()得到特征list的下标&lt;/li&gt;
&lt;li&gt;函数transform()将新的文本向量化&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通常情况下，每个特征权重会取tf-idf值，这个时候就应该使用 &lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer"&gt;TfidfVectorizer&lt;/a&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.feature_extraction.text&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;TfidfVectorizer&lt;/span&gt;
&lt;span class="n"&gt;vectorizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TfidfVectorizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;min_df&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;use_idf&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;vectorizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;corpus&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;features&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;vectorizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_feature_names&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;idf&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vectorizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;idf_&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="si"&gt;%.5f&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;idf&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c"&gt;# and   1.91629&lt;/span&gt;
&lt;span class="c"&gt;# document  1.22314&lt;/span&gt;
&lt;span class="c"&gt;# first 1.51083&lt;/span&gt;
&lt;span class="c"&gt;# is    1.22314&lt;/span&gt;
&lt;span class="c"&gt;# one   1.91629&lt;/span&gt;
&lt;span class="c"&gt;# second    1.91629&lt;/span&gt;
&lt;span class="c"&gt;# the   1.00000&lt;/span&gt;
&lt;span class="c"&gt;# third 1.91629&lt;/span&gt;
&lt;span class="c"&gt;# this  1.22314&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;TfidfVectorizer成员函数与CountVectorizer一样，但是多了成员变量idf_,&amp;nbsp;为每个特征idf值构成的list。如果仅仅需要统计一份idf词表出来，也可以用TfidfVectorizer，idf计算公式为log((N+1)/(df+1))+1，分子分母都+1是假定增加一篇文档包含所有词。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;其他说明&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果有自己的词表，相当于预先指定了特征，那么可以用 &lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html#sklearn.feature_extraction.DictVectorizer"&gt;DictVectorizer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;如果需要考虑短语或多词表达式，或者说考虑词之间的次序依赖关系，那么可以引入ngram模型，当ngram特征非常大的时候，需要考虑使用 &lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html#sklearn.feature_extraction.text.HashingVectorizer"&gt;HashingVectorizer&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="3"&gt;3.&amp;nbsp;分类实验&lt;/h4&gt;
&lt;p&gt;直接参考文章： &lt;a href="http://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html#example-text-document-classification-20newsgroups-py"&gt;Classification of text documents using sparse&amp;nbsp;features&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;演示常见分类算法的效果，并且还使用卡方测试选取有效文本特征进行降维后再进行分类，运行结果如下：&lt;/p&gt;
&lt;p&gt;&lt;img alt="20newsgroup" src="/images/20newsgroup.png" /&gt;&lt;/p&gt;
&lt;h3 id="_3"&gt;相关参考&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://scikit-learn.org/"&gt;scikit-learn官网&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://scikit-learn.org/stable/modules/feature_extraction.html"&gt;特征选择&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="sklearn"></category><category term="机器学习"></category></entry><entry><title>厦门三日游</title><link href="/posts/2015/05/10/sha-men-san-ri-you.html" rel="alternate"></link><updated>2015-05-10T00:00:00+08:00</updated><author><name>lostfish</name></author><id>tag:,2015-05-10:posts/2015/05/10/sha-men-san-ri-you.html</id><summary type="html">&lt;p&gt;从5月8日到5月10日，跟着豪华旅行团，在厦门开心地玩了3天。&lt;/p&gt;
&lt;h3 id="_1"&gt;第一天&lt;/h3&gt;
&lt;p&gt;下午坐动车去，落脚酒店,安顿下来后，去夜市逛了逛。&lt;/p&gt;
&lt;h3 id="_2"&gt;第二天&lt;/h3&gt;
&lt;p&gt;这一天包括了主要的行程：上午先在海边骑了自行车，然后去了炮台，下午则去了这次旅行的主要目标——鼓浪屿岛。
&lt;img alt="海滩" src="/images/xiamen1_hai.png" /&gt;
&lt;img alt="炮台" src="/images/xiamen2_paotai.png" /&gt;
&lt;img alt="鼓浪屿" src="/images/xiamen3_gulangyu.png" /&gt;
&lt;img alt="鼓浪屿" src="/images/xiamen4_gulangyu.png" /&gt;&lt;/p&gt;
&lt;h3 id="_3"&gt;第三天&lt;/h3&gt;
&lt;p&gt;去了南普陀和厦门大学。因为赶车，比较匆忙地看了看。
&lt;img alt="厦大校门" src="/images/xiamen5_daxue.png" /&gt;
&lt;img alt="厦大校内" src="/images/xiamen6_daxue.png" /&gt;&lt;/p&gt;</summary><category term="xiamen"></category><category term="travel"></category></entry><entry><title>建站备忘</title><link href="/posts/2015/01/24/jian-zhan-bei-wang.html" rel="alternate"></link><updated>2015-01-24T00:00:00+08:00</updated><author><name>lostfish</name></author><id>tag:,2015-01-24:posts/2015/01/24/jian-zhan-bei-wang.html</id><summary type="html">&lt;p&gt;一直想着搭建一个自己的网站，这次终于付诸行动了。参考了网上的许多资料，所以在这里就简单记录下自己的建站过程。&lt;/p&gt;
&lt;h3 id="_1"&gt;购买域名&lt;/h3&gt;
&lt;p&gt;从godaddy购买域名。也可用选择从万网和新网购买域名，这些网站还提供一条龙的服务，如提供主机，帮助备案等。&lt;/p&gt;
&lt;h3 id="_2"&gt;选择托管网站的主机&lt;/h3&gt;
&lt;p&gt;购买虚拟主机或者&lt;span class="caps"&gt;VPS&lt;/span&gt;，也可选择存储在github上，我选择的后者（以后有时间再买个主机试试）。如果要将网页放在github上，需要申请一个github账号，并创建一个与帐号同名的项目。具体参考 &lt;a href="https://help.github.com/categories/github-pages-basics/"&gt;GitHub Pages&lt;/a&gt;。 &lt;/p&gt;
&lt;h3 id="_3"&gt;生成网页&lt;/h3&gt;
&lt;p&gt;Github推荐使用Jekyll构建自己的github&amp;nbsp;pages。由于偏好python，我选择的pelican（鹈鹕）。Pelican是一个python包，使用pelican生成博客框架的过程如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;sudo apt-get install python-pip
pip install pelican
pip install markdown
mkdir myblog
cd myblog
pelican-quickstart
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;在myblog/content目录下编写markdown文件：test.md,然后在myblog目录下执行如下命令：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;make html
make serve
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;在myblog/output目录下会生成页面，同时在浏览器输入&lt;em&gt;localhost:8000&lt;/em&gt;可以查看结果。&lt;/p&gt;
&lt;p&gt;Markdown语法可参考 &lt;a href="https://help.github.com/articles/markdown-basics/"&gt;Markdown Basics&lt;/a&gt;，Ubuntu-14.04下貌似默认安装了编辑器retext。&lt;/p&gt;
&lt;p&gt;此外，需要加入如下几个功能：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;选择博客主题。下载pelican主题项目进行配置。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;git clone --recursive https://github.com/getpelican/pelican-themes.git
cd pelican-themes
pelican-themes -i ./pelican-themes/elegent
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;增加sitemap。下载pelican插件项目进行配置。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;git clone https://github.com/getpelican/pelican-plugins
cd pelican-plguins
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;增加评论。&lt;a href="https://disqus.com/"&gt;disqus&lt;/a&gt;提供了评论功能，注册账号即可获取一个shortname，将shortname加入pelicanconf.py,生成的页面中就会加入评论功能。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;增加站长统计。可选择google或者百度的站长工具。如果选择gogole，在 &lt;a href="http://www.google.com/analytics"&gt;Google Analytics&lt;/a&gt; 创建帐号，将追踪&lt;span class="caps"&gt;ID&lt;/span&gt;加入pelicanconf.py，生成页面中就会加入追踪功能。在 &lt;a href="http://www.google.com/webmasters"&gt;Google Webmasters&lt;/a&gt;&amp;nbsp;可查看追踪结果。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;最后，配置文件myblog/pelicanconf.py基本如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;AUTHOR = u&amp;#39;lostfish&amp;#39;
SITENAME = u&amp;quot;lostfish&amp;quot;
SITEURL = &amp;#39;http://tangke.me&amp;#39;
THEME = &amp;#39;elegent&amp;#39;
DISQUS_SITENAME = &amp;#39;disqus提供的shortname&amp;#39;
GOOGLE_ANALYTICS = &amp;#39;google提供的追踪id&amp;#39;

PATH = &amp;#39;content&amp;#39; #网页内容对应的markdown文件路径
...
# 设置生成页面存储路径为pots/年/月/日/{slug}.html (slug即文章标题拼音)
USE_FOLDER_AS_CATEGORY = False
ARTICLE_URL = &amp;#39;posts/{date:%Y}/{date:%m}/{date:%d}/{slug}.html&amp;#39;
ARTICLE_SAVE_AS = &amp;#39;posts/{date:%Y}/{date:%m}/{date:%d}/{slug}.html&amp;#39;
PAGE_URL = &amp;#39;pages/{slug}.html&amp;#39;
PAGE_SAVE_AS = &amp;#39;pages/{slug}.html&amp;#39;
YEAR_ARCHIVE_SAVE_AS = &amp;#39;posts/{date:%Y}/index.html&amp;#39;
MONTH_ARCHIVE_SAVE_AS = &amp;#39;posts/{date:%Y}/{date:%m}/index.html&amp;#39;

#站点地图插件配置
PLUGIN_PATHS = [&amp;quot;pelican-plugins&amp;quot;]
PLUGINS = [&amp;#39;sitemap&amp;#39;, &amp;#39;extract_toc&amp;#39;, &amp;#39;tipue_search&amp;#39;, &amp;#39;liquid_tags.img&amp;#39;,
            &amp;#39;neighbors&amp;#39;, &amp;#39;latex&amp;#39;, &amp;#39;related_posts&amp;#39;, &amp;#39;share_post&amp;#39;]
SITEMAP = {
    &amp;#39;format&amp;#39;: &amp;#39;xml&amp;#39;,
    &amp;#39;priorities&amp;#39;: {
        &amp;#39;articles&amp;#39;: 0.7,
        &amp;#39;indexes&amp;#39;: 0.5,
        &amp;#39;pages&amp;#39;: 0.3,
    },
    &amp;#39;changefreqs&amp;#39;: {
        &amp;#39;articles&amp;#39;: &amp;#39;monthly&amp;#39;,
        &amp;#39;indexes&amp;#39;: &amp;#39;daily&amp;#39;,
        &amp;#39;pages&amp;#39;: &amp;#39;monthly&amp;#39;
    }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="_4"&gt;绑定域名&lt;/h3&gt;
&lt;p&gt;将自己购买的域名与github&amp;nbsp;page绑定在一起需要3步：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在github pages项目下增加文件&lt;span class="caps"&gt;CNAME&lt;/span&gt;，在该文件中加入购买的域名。&lt;/li&gt;
&lt;li&gt;在godaddy中将购买域名对应的域名解析服务器绑定到dnspod的服务器，可参考: &lt;a href="https://support.dnspod.cn/Kb/showarticle/?qtype=%E5%8A%9F%E8%83%BD%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B&amp;amp;tsid=42"&gt;Godaddy注册商域名修改&lt;span class="caps"&gt;DNS&lt;/span&gt;地址&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;注册dnspod账户，将自己购买的域名与github的服务器绑定,建立两条A类记指向192.30.252.153和192.30.252.154（这个&lt;span class="caps"&gt;IP&lt;/span&gt;可能会变化，参考github上 &lt;a href="https://help.github.com/articles/tips-for-configuring-an-a-record-with-your-dns-provider/"&gt;教程&lt;/a&gt;）。另外，这个配置最晚可能要等72小时之后才生效。  &lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="_5"&gt;有用参考&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://docs.getpelican.com/en/3.5.0/settings.html"&gt;Pelican官方文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.pelicanthemes.com/"&gt;Pelican主题列表&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://oncrashreboot.com/elegant-best-pelican-theme-features"&gt;主题elegent配置说明&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="web"></category><category term="github"></category><category term="pelican"></category></entry></feed>