<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>当你老了</title><link href="/" rel="alternate"></link><link href="/feeds/all.atom.xml" rel="self"></link><id>/</id><updated>2016-08-27T00:00:00+08:00</updated><entry><title>Eclat算法实现</title><link href="/posts/2016/08/27/eclatsuan-fa-shi-xian.html" rel="alternate"></link><updated>2016-08-27T00:00:00+08:00</updated><author><name>lostfish</name></author><id>tag:,2016-08-27:posts/2016/08/27/eclatsuan-fa-shi-xian.html</id><summary type="html">&lt;h3 id="_1"&gt;基本原理&lt;/h3&gt;
&lt;p&gt;Eclat是挖掘频繁项集的一种算法，相比较而言远，它远没有另外两种算法Apriori和&lt;span class="caps"&gt;FP&lt;/span&gt;-Growth那么出名，一个直接的证明就是以前读书的时候课本都没有介绍。&lt;/p&gt;
&lt;p&gt;不过这个算法也有它自身的特点，基本原理和Apriori算法很相似，也是通过频繁K项集连接生成频繁K+1项集，但是比Apriori速度快很多，因为引入了倒排机制，保留了每个频繁项集对应的所有记录。这样，在连接生成频繁K+1项集的过程中，两个频繁K项集对应记录集合求交，就得到了这个K+1项集对应的记录集合，这个集合的size就是K+1项集的出现频数，通过与支持度比较就可以判断新产生的K+1项集是不是频繁的。从这个过程可以看出，Eclat算法只需要扫描一次记录库，而Apriori算法每次判断候选K+1项集是不是频繁的时候都要扫描一次记录库，所以Eclat比Apriori快也就不奇怪了。不难看出，Eclat算法其实是用空间换取了时间，后续实验也证明了这个算法是比较耗费空间的。&lt;/p&gt;
&lt;p&gt;举个例子（参考[1])：&amp;nbsp;有4条记录&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;tid item
1   A,B
2   B,C
3   A,C
4   A,B,C
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;设定最小支持度为2，第一边扫描记录库后，得到频繁1项集，其中每个item对应的记录集合也保留了，如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;item  tids  freq
A     1,3,4 3
B     1,2,4 3
C     2,3,4 3
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;由频繁1项集连接生成候选2项集，都是频繁的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;item tids freq
A,B  1,4  2
A,C  3,4  2
B,C  2,4  2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;由频繁2项集连接生成候选3项集，只有一个候选并且不是频繁的，算法结束：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;item    tids freq
A,B,C   4    1
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：在最后一步中，只有A,B和A,C前缀相同，可以连接&lt;/p&gt;
&lt;h3 id="_2"&gt;实现思路&lt;/h3&gt;
&lt;p&gt;尝试用C++进行了基本的实现。这里总结几个要点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;所有item都转换为整数表示，项集用存储item的有序vector表示，这样连接生成K+1项集的时候方便快速比较前缀&lt;/li&gt;
&lt;li&gt;每个频繁项集和记录集合的映射关系用map，记录集合用set（貌似比较耗费空间，可能用位图可以优化）&lt;/li&gt;
&lt;li&gt;连接过程关键是比较前缀，比如有两个K项集，那么比较前k-1项是否相同，相同就把其中一个K项集最后一项追加到另一个最后，构成K+1项集，追加后要保证K+1项集是有序的。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;从算法过程中还可以看出：频繁K项集的计算，需要把前面频繁1,2，..,&amp;nbsp;k-1项集都计算后才能进行。此外，频繁1项集和频繁2项集的计算需要特殊处理，不用比较前缀。&lt;/p&gt;
&lt;p&gt;具体实现参考代码：&lt;a href="https://github.com/lostfish/eclat"&gt;https://github.com/lostfish/eclat&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="_3"&gt;实验结果&lt;/h3&gt;
&lt;p&gt;测试数据采用和[2]相同的mushroom.dat，该数据集下载地址为[3]，下载后需要去掉每行最后的空格。&lt;/p&gt;
&lt;p&gt;机器配置为：Intel(R) Xeon(R) &lt;span class="caps"&gt;CPU&lt;/span&gt; E5606  @ 2.13GHz&amp;nbsp;(8核，32G内存)&lt;/p&gt;
&lt;p&gt;测试结果如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;最小支持度  频繁项集数  运行时间
812(0.1)    574513  29.219
1218(0.15)  98575   4.593
1624(0.2)   53663   2.632
2031(0.25)  5545    0.603
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;当支持度为812时，挖掘的各频繁项集数目如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;valid_num&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;8124&lt;/span&gt; &lt;span class="mi"&gt;8124&lt;/span&gt;
&lt;span class="n"&gt;uniq&lt;/span&gt; &lt;span class="n"&gt;id&lt;/span&gt; &lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;119&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    &lt;span class="mi"&gt;56&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    &lt;span class="mi"&gt;763&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    &lt;span class="mi"&gt;4599&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    &lt;span class="mi"&gt;16171&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    &lt;span class="mi"&gt;38829&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    &lt;span class="mi"&gt;69854&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    &lt;span class="mi"&gt;98852&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    &lt;span class="mi"&gt;111787&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;    &lt;span class="mi"&gt;100660&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;   &lt;span class="mi"&gt;71342&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;   &lt;span class="mi"&gt;39171&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;   &lt;span class="mi"&gt;16292&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;   &lt;span class="mi"&gt;4956&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;   &lt;span class="mi"&gt;1039&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;   &lt;span class="mi"&gt;134&lt;/span&gt;
&lt;span class="n"&gt;frequent&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;itemset&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;   &lt;span class="mi"&gt;8&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;同时还观察了下空间消耗，占用内存达到了将近9G，比较惊人。当然这个数据集合本身频繁模式就比较多，平时应用中一般也不需要计算所有频繁项集，一般到频繁3项集或4项集就够了。另外算法本身也可以优化，比如记录集合用位图来表示。&lt;/p&gt;
&lt;h3 id="_4"&gt;相关参考&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;[1] &lt;a href="https://zh.wikipedia.org/zh/%E5%85%B3%E8%81%94%E5%BC%8F%E8%A7%84%E5%88%99"&gt;https://zh.wikipedia.org/zh/%E5%85%B3%E8%81%94%E5%&lt;span class="caps"&gt;BC&lt;/span&gt;%8F%E8%A7%84%E5%88%99&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[2] &lt;a href="http://blog.csdn.net/yangliuy/article/details/7494983"&gt;http://blog.csdn.net/yangliuy/article/details/7494983&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[3] &lt;a href="http://blog.csdn.net/yangliuy/article/details/7494983"&gt;http://fimi.ua.ac.be/data/mushroom.dat&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="eclat"></category><category term="频繁项集挖掘"></category></entry><entry><title>python代理下载</title><link href="/posts/2016/07/22/pythondai-li-xia-zai.html" rel="alternate"></link><updated>2016-07-22T00:00:00+08:00</updated><author><name>lostfish</name></author><id>tag:,2016-07-22:posts/2016/07/22/pythondai-li-xia-zai.html</id><summary type="html">&lt;p&gt;当用同一个ip不断地去爬取一个网站的时候，很可能封掉，这时候就需要用到代理来分散请求。&lt;/p&gt;
&lt;h3 id="_1"&gt;分两种情况&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;代理设置了dns，调用函数crawl_page2()&lt;/li&gt;
&lt;li&gt;代理没有设置dns，调用函数crawl_page()，这种情况稍微复杂点，先要获取url域名对应的ip地址，给http请求包加上dest_ip字段&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="_2"&gt;代码如下&lt;/h3&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/usr/bin/env python&lt;/span&gt;
&lt;span class="c"&gt;# encoding:utf-8&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;urllib2&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;socket&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;struct&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_dest_ip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;domain&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;ip_addr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;socket&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gethostbyname&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;domain&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c"&gt;#just for ipv4&lt;/span&gt;
    &lt;span class="c"&gt;#ip_addr = socket.getaddrinfo(domain, &amp;#39;http&amp;#39;)[0][4][0]&lt;/span&gt;
    &lt;span class="c"&gt;#[(2, 1, 6, &amp;#39;&amp;#39;, (&amp;#39;14.215.177.38&amp;#39;, 80)), (2, 2, 17, &amp;#39;&amp;#39;, (&amp;#39;14.215.177.38&amp;#39;, 80)), (2, 1, 6, &amp;#39;&amp;#39;, (&amp;#39;14.215.177.37&amp;#39;, 80)), (2, 2, 17, &amp;#39;&amp;#39;, (&amp;#39;14.215.177.37&amp;#39;, 80))]&lt;/span&gt;
    &lt;span class="n"&gt;uint32_binary_str&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;socket&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;inet_aton&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ip_addr&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;unpack_result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;struct&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unpack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;!I&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;uint32_binary_str&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ip_int&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;socket&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;htonl&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;unpack_result&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; 
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;ip_int&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;crawl_page&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dest_ip&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cur_proxy&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
    &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;
    &lt;span class="n"&gt;myheaders&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;User-Agent&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.2; .NET CLR 1.0.3705;)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
        &lt;span class="s"&gt;&amp;quot;Proxy-Connection&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Keep-Alive&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s"&gt;&amp;quot;dest_ip&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;dest_ip&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;http://&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;cur_proxy&lt;/span&gt;
    &lt;span class="n"&gt;h&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ProxyHandler&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;http&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
    &lt;span class="n"&gt;o&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;build_opener&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;HTTPHandler&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;addheaders&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;myheaders&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;timeout&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;HTTPError&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Error Code:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;404&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;No page: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;URLError&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Error Reason:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reason&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;Exception&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Error&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Good&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Bad&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;content&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;crawl_page2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cur_proxy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;    get&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="c"&gt;#    print &amp;quot;--&amp;gt;crawl comment: %s&amp;quot; % url&lt;/span&gt;
&lt;span class="c"&gt;#    print &amp;quot;--&amp;gt;cur_proxy: %s&amp;quot; % cur_proxy&lt;/span&gt;
    &lt;span class="n"&gt;myheaders&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;User-Agent&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.2; .NET CLR 1.0.3705;)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;cur_proxy&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;proxy_handler&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ProxyHandler&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;http&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;cur_proxy&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
            &lt;span class="n"&gt;opener&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;build_opener&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;proxy_handler&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;opener&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;timeout&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;req&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Request&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;headers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;myheaders&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;req&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;timeout&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;HTTPError&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Error Code:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;404&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;No page: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;URLError&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Error Reason:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reason&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;Exception&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Error&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;content&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="c"&gt;# open proxys&lt;/span&gt;
    &lt;span class="n"&gt;proxy_list&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;readlines&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;http://www.baidu.com&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;host&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;www.baidu.com&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;dest_ip&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;get_dest_ip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;host&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;proxy_list&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;n1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;crawl_page&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dest_ip&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;crawl_page len:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n1&lt;/span&gt;
        &lt;span class="n"&gt;n2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;crawl_page2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;crawl_page2 len:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;h3 id="_3"&gt;测试输出&lt;/h3&gt;
&lt;p&gt;输入文件为两个代理ip，一个配置了dns，一个没有配置dns&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;Good    http://10.183.27.147:32810
crawl_page len: 10811
crawl_page2 len: 10811
Good    http://10.184.16.44:32810
crawl_page len: 10811
Error Reason: timed out
crawl_page2 len: 0
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="_4"&gt;其他说明&lt;/h3&gt;
&lt;p&gt;获取dest_ip是访问的dns服务，并不是访问的原网站，而dns是带本地cache，所以频繁访问应该是没有问题的。&lt;/p&gt;
&lt;p&gt;函数get_dest_ip()中调用了socket模块的相关函数:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;socket.gethostbyname()&amp;nbsp;获取域名对应ip，只支持ipv4，若需要支持ipv6，可使用函数socket.getaddrinfo()&lt;/li&gt;
&lt;li&gt;socket.inet_aton()&amp;nbsp;转换ip地址（192.168.1.10）为32位打包二进制字符串，只支持ipv4，若需要支持ipv6，可使用函数socket.inet_pton()&lt;/li&gt;
&lt;li&gt;socket.htonl()&amp;nbsp;将32位整数从主机字节序转换成网络字节序&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="_5"&gt;参考&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.programgo.com/article/11342723643/"&gt;http://www.programgo.com/article/11342723643/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cnblogs.com/gala/archive/2011/09/22/2184801.html"&gt;http://www.cnblogs.com/gala/archive/2011/09/22/2184801.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="python"></category><category term="代理"></category><category term="下载"></category></entry><entry><title>青海行</title><link href="/posts/2016/07/03/qing-hai-xing.html" rel="alternate"></link><updated>2016-07-03T00:00:00+08:00</updated><author><name>lostfish</name></author><id>tag:,2016-07-03:posts/2016/07/03/qing-hai-xing.html</id><summary type="html">&lt;p&gt;六月是个好月份，适合旅行。&lt;/p&gt;
&lt;p&gt;从22号到26号共五天的时间里，跟团去大青海体验了祖国西部的大好河山。&lt;/p&gt;
&lt;h3 id="_1"&gt;启程&lt;/h3&gt;
&lt;p&gt;傍晚时分，天气正好，带一丝燥热，跟随大队伍从深圳宝启程啦。
&lt;img alt="青海" src="/images/qinghai1_hai.png" /&gt;&lt;/p&gt;
&lt;p&gt;有点漫长的旅程，飞着飞着天就黑了。&lt;/p&gt;
&lt;p&gt;到西宁的时候，已经是午夜。一下飞机就感受到了大西部的寒冷。后面更是感觉到了干燥和缺氧。&lt;/p&gt;
&lt;h3 id="_2"&gt;第一站&lt;/h3&gt;
&lt;p&gt;青海湖，美，辽阔，Relaxing！&lt;/p&gt;
&lt;h3 id="_3"&gt;第二站&lt;/h3&gt;
&lt;p&gt;茶卡盐湖，白，天空之境，特别的美。&lt;/p&gt;
&lt;h3 id="_4"&gt;第三站&lt;/h3&gt;
&lt;p&gt;沙岛，还是青海湖，但是体验沙漠游玩项目：骑骆驼，骑摩托，滑沙。&lt;/p&gt;
&lt;h3 id="_5"&gt;最后一站&lt;/h3&gt;
&lt;p&gt;彩虹部落&lt;/p&gt;</summary><category term="qinghai"></category><category term="travel"></category></entry><entry><title>sklearn使用笔记</title><link href="/posts/2015/07/04/sklearnshi-yong-bi-ji.html" rel="alternate"></link><updated>2015-07-04T00:00:00+08:00</updated><author><name>lostfish</name></author><id>tag:,2015-07-04:posts/2015/07/04/sklearnshi-yong-bi-ji.html</id><summary type="html">&lt;p&gt;sklearn全称为scikit-learn，是目前很流行的一个基于python的机器学习包，基本覆盖了常见的机器学习算法，如分类、回归、聚类、特征选择、模型选择以及数据预处理等任务对应的算法。文档和示例非常丰富，可视化展示也很方便，所以使用者众多，尤其是在 &lt;a href="!https://www.kaggle.com/"&gt;Kaggle&lt;/a&gt;&amp;nbsp;数据分析竞赛中被参赛者广泛使用。&lt;/p&gt;
&lt;p&gt;关于该工具包的使用介绍网上已经非常多，所以这里只是整理和记录自己使用的一些心得。&lt;/p&gt;
&lt;h3 id="_1"&gt;初始入门&lt;/h3&gt;
&lt;p&gt;最好入门方法就是参考官网的 &lt;a href="!http://scikit-learn.org/stable/tutorial/index.html"&gt;Tutorials&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;sklearn集成了一些常用的数据集，以方便测试相关算法，封装为datasets模块，如导入分类数据集合iris和digits，导入回归数据集diabetes&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;
&lt;span class="n"&gt;iris&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load_iris&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;digits&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load_digits&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;diabetes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load_diabetes&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;具体如何在这些数据集合应用相关算法，官网Tutorials有详细的介绍，下面重点讲下文本分类。&lt;/p&gt;
&lt;h3 id="_2"&gt;文本分类&lt;/h3&gt;
&lt;h4 id="1"&gt;1.&amp;nbsp;加载数据&lt;/h4&gt;
&lt;p&gt;数据集选取的是20newsgroups，该数据集包含20个新闻组约2万篇文档，加载方式也是通过sklearn.datasets模块，但是稍有不同，如下&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;fetch_20newsgroups&lt;/span&gt;
&lt;span class="n"&gt;categories&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;alt.atheism&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;soc.religion.christian&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;comp.graphics&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;sci.med&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;twenty_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fetch_20newsgroups&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;subset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;train&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;categories&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;categories&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shuffle&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;从上面可以看出，加载数据集实际上是调用函数fetch_20newsgroups()&lt;/p&gt;
&lt;p&gt;在python命令行输入help(fetch_20newsgroups），可以查看相应参数说明，其中&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;subset: 指定加载训练集或测试集，或者两者，取值对应&amp;#8217;train&amp;#8217;, &amp;#8216;test&amp;#8217;,&amp;nbsp;&amp;#8216;all&amp;#8217;&lt;/li&gt;
&lt;li&gt;data_home: 指定20newsgroups数据集所在路径，默认为&amp;nbsp;&amp;#8216;~/scikit_learn_data&amp;#8217;，Windows下对应为C:\Users\xxx\scikit_learn_data&lt;/li&gt;
&lt;li&gt;categories:&amp;nbsp;指定要加载的类别list，默认为None，表示所有类别&lt;/li&gt;
&lt;li&gt;shuffle：&amp;nbsp;是否要混洗数据&lt;/li&gt;
&lt;li&gt;random_state：&amp;nbsp;混洗随机数的种子值&lt;/li&gt;
&lt;li&gt;download_if_missing：&amp;nbsp;指定data_home下不存在数据集时是否下载，默认为True，表示下载&lt;/li&gt;
&lt;li&gt;remove： 指定预处理文本的过滤策略，取值为元组 (&amp;#8216;headers&amp;#8217;, &amp;#8216;footers&amp;#8217;,&amp;nbsp;&amp;#8216;quotes&amp;#8217;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;刚开始测试这个数据集的时候，老是等半天没有结果。于是看了下对应的源代码./site-packages/sklearn/datasets/twenty_newsgroups.py，发现第一次加载的时候会下载数据集到~/scikit_learn_data/20news_home，下载完成后会解压然后压缩生成cache文件，即~/scikit_learn_data/20news-bydate.pkz，以后每次加载就读取该文件了。&lt;/p&gt;
&lt;p&gt;所以首次加载的时候需要有点耐心，大概等待7分钟左右吧（国内环境）。&lt;/p&gt;
&lt;p&gt;当然也可以自己下载放到目录~/scikit_learn_data/20news_home，下载地址为：&lt;a href="http://people.csail.mit.edu/jrennie/20Newsgroups/20news-bydate.tar.gz"&gt;http://people.csail.mit.edu/jrennie/20Newsgroups/20news-bydate.tar.gz&lt;/a&gt;&amp;nbsp;（文件大小为13.7M）&lt;/p&gt;
&lt;h4 id="2"&gt;2.&amp;nbsp;特征选择&lt;/h4&gt;
&lt;p&gt;最常见的就是词袋模型，每个词就是一个特征，特征权重为词频, 通过构建 &lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer"&gt;CountVectorizer&lt;/a&gt;&amp;nbsp;来向量化每篇文档：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.feature_extraction.text&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;CountVectorizer&lt;/span&gt;

&lt;span class="n"&gt;vectorizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;CountVectorizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;min_df&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;corpus&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
    &lt;span class="s"&gt;&amp;#39;This is the first document.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s"&gt;&amp;#39;This is the second second document.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s"&gt;&amp;#39;And the third one.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s"&gt;&amp;#39;Is this the first document?&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;vectorizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;corpus&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;vectorizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_feature_names&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="c"&gt;#[u&amp;#39;and&amp;#39;, u&amp;#39;document&amp;#39;, u&amp;#39;first&amp;#39;, u&amp;#39;is&amp;#39;, u&amp;#39;one&amp;#39;, u&amp;#39;second&amp;#39;, u&amp;#39;the&amp;#39;, u&amp;#39;third&amp;#39;, u&amp;#39;this&amp;#39;]&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vectorizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocabulary_&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c"&gt;# and   0&lt;/span&gt;
&lt;span class="c"&gt;# document  1&lt;/span&gt;
&lt;span class="c"&gt;# first 2&lt;/span&gt;
&lt;span class="c"&gt;# is    3&lt;/span&gt;
&lt;span class="c"&gt;# one   4&lt;/span&gt;
&lt;span class="c"&gt;# second    5&lt;/span&gt;
&lt;span class="c"&gt;# the   6&lt;/span&gt;
&lt;span class="c"&gt;# third 7&lt;/span&gt;
&lt;span class="c"&gt;# this  8&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;toarray&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="c"&gt;# [[0 1 1 1 0 0 1 0 1]]&lt;/span&gt;
&lt;span class="c"&gt;# [[0 1 0 1 0 2 1 0 1]]&lt;/span&gt;
&lt;span class="c"&gt;# [[1 0 0 0 1 0 1 1 0]]&lt;/span&gt;
&lt;span class="c"&gt;# [[0 1 1 1 0 0 1 0 1]]&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;vectorizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transform&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Something completely new.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;toarray&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="c"&gt;# [[0 0 0 0 0 0 0 0 0]]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;上面代码中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;函数fit_transform()会在训练数据上训练一个Vectorizer，并将训练数据向量化，由于文本特征维度较高，这里是用稀疏矩阵保存&lt;/li&gt;
&lt;li&gt;函数get_feature_names()得到特征名称的list,&amp;nbsp;特征名称为unicode字符串，而vectorizer的成员变量vocabulary_恰好是特征名称到特征索引的dict，这个索引就是get_feature_names()得到特征list的下标&lt;/li&gt;
&lt;li&gt;函数transform()将新的文本向量化&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通常情况下，每个特征权重会取tf-idf值，这个时候就应该使用 &lt;a href="!http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer"&gt;TfidfVectorizer&lt;/a&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.feature_extraction.text&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;TfidfVectorizer&lt;/span&gt;
&lt;span class="n"&gt;vectorizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TfidfVectorizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;min_df&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;use_idf&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;vectorizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;corpus&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;features&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;vectorizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_feature_names&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;idf&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vectorizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;idf_&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="si"&gt;%.5f&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;idf&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c"&gt;# and   1.91629&lt;/span&gt;
&lt;span class="c"&gt;# document  1.22314&lt;/span&gt;
&lt;span class="c"&gt;# first 1.51083&lt;/span&gt;
&lt;span class="c"&gt;# is    1.22314&lt;/span&gt;
&lt;span class="c"&gt;# one   1.91629&lt;/span&gt;
&lt;span class="c"&gt;# second    1.91629&lt;/span&gt;
&lt;span class="c"&gt;# the   1.00000&lt;/span&gt;
&lt;span class="c"&gt;# third 1.91629&lt;/span&gt;
&lt;span class="c"&gt;# this  1.22314&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;TfidfVectorizer成员函数与CountVectorizer一样，但是多了成员变量idf_,&amp;nbsp;为每个特征idf值构成的list。如果仅仅需要统计一份idf词表出来，也可以用TfidfVectorizer，idf计算公式为log((N+1)/(df+1))+1，分子分母都+1是假定增加一篇文档包含所有词。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;其他说明&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果有自己的词表，相当于预先指定了特征，那么可以用 &lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html#sklearn.feature_extraction.DictVectorizer"&gt;DictVectorizer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;如果需要考虑短语或多词表达式，或者说考虑词之间的次序依赖关系，那么可以引入ngram模型，当ngram特征非常大的时候，需要考虑使用 &lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html#sklearn.feature_extraction.text.HashingVectorizer"&gt;HashingVectorizer&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="3"&gt;3.&amp;nbsp;分类实验&lt;/h4&gt;
&lt;p&gt;直接参考文章： &lt;a href="http://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html#example-text-document-classification-20newsgroups-py"&gt;Classification of text documents using sparse&amp;nbsp;features&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;演示常见分类算法的效果，并且还使用卡方测试选取有效文本特征进行降维后再进行分类，运行结果如下：&lt;/p&gt;
&lt;p&gt;&lt;img alt="20newsgroup" src="/images/20newsgroups.png" /&gt;&lt;/p&gt;
&lt;h3 id="_3"&gt;相关参考&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://scikit-learn.org/"&gt;scikit-learn官网&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://scikit-learn.org/stable/modules/feature_extraction.html"&gt;特征选择&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="sklearn"></category><category term="机器学习"></category></entry><entry><title>厦门三日游</title><link href="/posts/2015/05/10/sha-men-san-ri-you.html" rel="alternate"></link><updated>2015-05-10T00:00:00+08:00</updated><author><name>lostfish</name></author><id>tag:,2015-05-10:posts/2015/05/10/sha-men-san-ri-you.html</id><summary type="html">&lt;p&gt;从5月8日到5月10日，跟着豪华旅行团，在厦门开心地玩了3天。&lt;/p&gt;
&lt;h3 id="_1"&gt;第一天&lt;/h3&gt;
&lt;p&gt;下午坐动车去，落脚酒店,安顿下来后，去夜市逛了逛。&lt;/p&gt;
&lt;h3 id="_2"&gt;第二天&lt;/h3&gt;
&lt;p&gt;这一天包括了主要的行程：上午先在海边骑了自行车，然后去了炮台，下午则去了这次旅行的主要目标——鼓浪屿岛。
&lt;img alt="海滩" src="/images/xiamen1_hai.png" /&gt;
&lt;img alt="炮台" src="/images/xiamen2_paotai.png" /&gt;
&lt;img alt="鼓浪屿" src="/images/xiamen3_gulangyu.png" /&gt;
&lt;img alt="鼓浪屿" src="/images/xiamen4_gulangyu.png" /&gt;&lt;/p&gt;
&lt;h3 id="_3"&gt;第三天&lt;/h3&gt;
&lt;p&gt;去了南普陀和厦门大学。因为赶车，比较匆忙地看了看。
&lt;img alt="厦大校门" src="/images/xiamen5_daxue.png" /&gt;
&lt;img alt="厦大校内" src="/images/xiamen6_daxue.png" /&gt;&lt;/p&gt;</summary><category term="xiamen"></category><category term="travel"></category></entry><entry><title>建站备忘</title><link href="/posts/2015/01/24/jian-zhan-bei-wang.html" rel="alternate"></link><updated>2015-01-24T00:00:00+08:00</updated><author><name>lostfish</name></author><id>tag:,2015-01-24:posts/2015/01/24/jian-zhan-bei-wang.html</id><summary type="html">&lt;p&gt;一直想着搭建一个自己的网站，这次终于付诸行动了。参考了网上的许多资料，所以在这里就简单记录下自己的建站过程。&lt;/p&gt;
&lt;h3 id="_1"&gt;购买域名&lt;/h3&gt;
&lt;p&gt;从godaddy购买域名。也可用选择从万网和新网购买域名，这些网站还提供一条龙的服务，如提供主机，帮助备案等。&lt;/p&gt;
&lt;h3 id="_2"&gt;选择托管网站的主机&lt;/h3&gt;
&lt;p&gt;购买虚拟主机或者&lt;span class="caps"&gt;VPS&lt;/span&gt;，也可选择存储在github上，我选择的后者（以后有时间再买个主机试试）。如果要将网页放在github上，需要申请一个github账号，并创建一个与帐号同名的项目。具体参考 &lt;a href="https://help.github.com/categories/github-pages-basics/"&gt;GitHub Pages&lt;/a&gt;。 &lt;/p&gt;
&lt;h3 id="_3"&gt;生成网页&lt;/h3&gt;
&lt;p&gt;Github推荐使用Jekyll构建自己的github&amp;nbsp;pages。由于偏好python，我选择的pelican（鹈鹕）。Pelican是一个python包，使用pelican生成博客框架的过程如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;sudo apt-get install python-pip
pip install pelican
pip install markdown
mkdir myblog
cd myblog
pelican-quickstart
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;在myblog/content目录下编写markdown文件：test.md,然后在myblog目录下执行如下命令：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;make html
make serve
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;在myblog/output目录下会生成页面，同时在浏览器输入&lt;em&gt;localhost:8000&lt;/em&gt;可以查看结果。&lt;/p&gt;
&lt;p&gt;Markdown语法可参考 &lt;a href="https://help.github.com/articles/markdown-basics/"&gt;Markdown Basics&lt;/a&gt;，Ubuntu-14.04下貌似默认安装了编辑器retext。&lt;/p&gt;
&lt;p&gt;此外，需要加入如下几个功能：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;选择博客主题。下载pelican主题项目进行配置。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;git clone --recursive https://github.com/getpelican/pelican-themes.git
cd pelican-themes
pelican-themes -i ./pelican-themes/elegent
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;增加sitemap。下载pelican插件项目进行配置。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;git clone https://github.com/getpelican/pelican-plugins
cd pelican-plguins
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;增加评论。&lt;a href="https://disqus.com/"&gt;disqus&lt;/a&gt;提供了评论功能，注册账号即可获取一个shortname，将shortname加入pelicanconf.py,生成的页面中就会加入评论功能。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;增加站长统计。可选择google或者百度的站长工具。如果选择gogole，在 &lt;a href="http://www.google.com/analytics"&gt;Google Analytics&lt;/a&gt; 创建帐号，将追踪&lt;span class="caps"&gt;ID&lt;/span&gt;加入pelicanconf.py，生成页面中就会加入追踪功能。在 &lt;a href="http://www.google.com/webmasters"&gt;Google Webmasters&lt;/a&gt;&amp;nbsp;可查看追踪结果。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;最后，配置文件myblog/pelicanconf.py基本如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;AUTHOR = u&amp;#39;lostfish&amp;#39;
SITENAME = u&amp;quot;lostfish&amp;quot;
SITEURL = &amp;#39;http://tangke.me&amp;#39;
THEME = &amp;#39;elegent&amp;#39;
DISQUS_SITENAME = &amp;#39;disqus提供的shortname&amp;#39;
GOOGLE_ANALYTICS = &amp;#39;google提供的追踪id&amp;#39;

PATH = &amp;#39;content&amp;#39; #网页内容对应的markdown文件路径
...
# 设置生成页面存储路径为pots/年/月/日/{slug}.html (slug即文章标题拼音)
USE_FOLDER_AS_CATEGORY = False
ARTICLE_URL = &amp;#39;posts/{date:%Y}/{date:%m}/{date:%d}/{slug}.html&amp;#39;
ARTICLE_SAVE_AS = &amp;#39;posts/{date:%Y}/{date:%m}/{date:%d}/{slug}.html&amp;#39;
PAGE_URL = &amp;#39;pages/{slug}.html&amp;#39;
PAGE_SAVE_AS = &amp;#39;pages/{slug}.html&amp;#39;
YEAR_ARCHIVE_SAVE_AS = &amp;#39;posts/{date:%Y}/index.html&amp;#39;
MONTH_ARCHIVE_SAVE_AS = &amp;#39;posts/{date:%Y}/{date:%m}/index.html&amp;#39;

#站点地图插件配置
PLUGIN_PATHS = [&amp;quot;pelican-plugins&amp;quot;]
PLUGINS = [&amp;#39;sitemap&amp;#39;, &amp;#39;extract_toc&amp;#39;, &amp;#39;tipue_search&amp;#39;, &amp;#39;liquid_tags.img&amp;#39;,
            &amp;#39;neighbors&amp;#39;, &amp;#39;latex&amp;#39;, &amp;#39;related_posts&amp;#39;, &amp;#39;share_post&amp;#39;]
SITEMAP = {
    &amp;#39;format&amp;#39;: &amp;#39;xml&amp;#39;,
    &amp;#39;priorities&amp;#39;: {
        &amp;#39;articles&amp;#39;: 0.7,
        &amp;#39;indexes&amp;#39;: 0.5,
        &amp;#39;pages&amp;#39;: 0.3,
    },
    &amp;#39;changefreqs&amp;#39;: {
        &amp;#39;articles&amp;#39;: &amp;#39;monthly&amp;#39;,
        &amp;#39;indexes&amp;#39;: &amp;#39;daily&amp;#39;,
        &amp;#39;pages&amp;#39;: &amp;#39;monthly&amp;#39;
    }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="_4"&gt;绑定域名&lt;/h3&gt;
&lt;p&gt;将自己购买的域名与github&amp;nbsp;page绑定在一起需要3步：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在github pages项目下增加文件&lt;span class="caps"&gt;CNAME&lt;/span&gt;，在该文件中加入购买的域名。&lt;/li&gt;
&lt;li&gt;在godaddy中将购买域名对应的域名解析服务器绑定到dnspod的服务器，可参考: &lt;a href="https://support.dnspod.cn/Kb/showarticle/?qtype=%E5%8A%9F%E8%83%BD%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B&amp;amp;tsid=42"&gt;Godaddy注册商域名修改&lt;span class="caps"&gt;DNS&lt;/span&gt;地址&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;注册dnspod账户，将自己购买的域名与github的服务器绑定,建立两条A类记指向192.30.252.153和192.30.252.154（这个&lt;span class="caps"&gt;IP&lt;/span&gt;可能会变化，参考github上 &lt;a href="https://help.github.com/articles/tips-for-configuring-an-a-record-with-your-dns-provider/"&gt;教程&lt;/a&gt;）。另外，这个配置最晚可能要等72小时之后才生效。  &lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="_5"&gt;有用参考&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://docs.getpelican.com/en/3.5.0/settings.html"&gt;Pelican官方文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.pelicanthemes.com/"&gt;Pelican主题列表&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://oncrashreboot.com/elegant-best-pelican-theme-features"&gt;主题elegent配置说明&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="web"></category><category term="github"></category><category term="pelican"></category></entry></feed>